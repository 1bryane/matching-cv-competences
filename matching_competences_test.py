#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üéØ Test du Matching de Comp√©tences avec TF-IDF et Flask

Ce fichier teste le code de base pour le matching de comp√©tences entre CVs et offres d'emploi
en utilisant TF-IDF (Term Frequency-Inverse Document Frequency) pour une meilleure pr√©cision.

Technologies utilis√©es :
- PyPDF2 : Extraction de texte depuis PDF
- TfidfVectorizer : Vectorisation TF-IDF optimis√©e des comp√©tences
- Cosine Similarity : Calcul de similarit√©
- Flask : API web pour tester
- NLTK : Pr√©traitement avanc√© du texte

‚ö†Ô∏è IMPORTANT : Ce fichier est ind√©pendant du projet principal ESPRIT
"""

from PyPDF2 import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import os
import json
import re
from flask import Flask, request, jsonify
from flask_cors import CORS
from tfidf_config import get_tfidf_config, get_quality_thresholds
from skills_preprocessor import create_preprocessor

print("‚úÖ Tous les imports sont charg√©s")



def extract_text_from_pdf(pdf_path):
    """
    Extrait le texte d'un fichier PDF
    
    Args:
        pdf_path (str): Chemin vers le fichier PDF
        
    Returns:
        str: Texte extrait du PDF
    """
    try:
        reader = PdfReader(pdf_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text()
        return text.strip()
    except Exception as e:
        print(f"‚ùå Erreur lors de l'extraction de {pdf_path}: {e}")
        return ""

def calculate_similarity_tfidf(cv_skills, job_skills):
    """
    Calcule la similarit√© entre comp√©tences CV et comp√©tences job en utilisant TF-IDF optimis√©
    
    Args:
        cv_skills (list): Liste des comp√©tences extraites des CVs
        job_skills (list): Liste des comp√©tences requises pour les jobs
        
    Returns:
        tuple: (matrice_similarit√©, meilleurs_matches, scores, vectoriseur)
    """
    try:
        # Cr√©ation du pr√©traiteur avanc√©
        preprocessor = create_preprocessor()
        
        # Pr√©traitement avanc√© des comp√©tences
        cv_skills_processed = preprocessor.preprocess_skills_batch(cv_skills)
        job_skills_processed = preprocessor.preprocess_skills_batch(job_skills)
        
        # Configuration TF-IDF optimis√©e
        tfidf_config = get_tfidf_config()
        
        # Cr√©ation du vectoriseur TF-IDF optimis√©
        vectorizer = TfidfVectorizer(**tfidf_config)
        
        # Combinaison de toutes les comp√©tences pour l'entra√Ænement
        all_skills = cv_skills_processed + job_skills_processed
        
        # Vectorisation TF-IDF
        tfidf_matrix = vectorizer.fit_transform(all_skills)
        
        # S√©paration des vecteurs CV et Job
        cv_vectors = tfidf_matrix[:len(cv_skills_processed)]
        job_vectors = tfidf_matrix[len(cv_skills_processed):]
        
        # Calcul de la similarit√© cosinus
        similarity_matrix = cosine_similarity(cv_vectors, job_vectors)
        
        # Trouver les meilleurs matches
        best_matches = np.argmax(similarity_matrix, axis=0)
        
        # Scores des meilleurs matches
        best_scores = np.max(similarity_matrix, axis=0)
        
        # Affichage des statistiques de pr√©traitement
        stats = preprocessor.get_skills_statistics(cv_skills + job_skills)
        print(f"üìä Statistiques de pr√©traitement: {stats['total_tokens']} tokens, {stats['unique_tokens']} uniques")
        
        return similarity_matrix, best_matches, best_scores, vectorizer
        
    except Exception as e:
        print(f"‚ùå Erreur lors du calcul de similarit√© TF-IDF: {e}")
        return None, None, None, None

def analyze_tfidf_features(vectorizer, cv_skills, job_skills):
    """
    Analyse les features TF-IDF pour comprendre le matching
    
    Args:
        vectorizer: Vectoriseur TF-IDF entra√Æn√©
        cv_skills (list): Comp√©tences des CVs
        job_skills (list): Comp√©tences des jobs
    """
    if vectorizer is None:
        return
    
    print("\nüîç Analyse des features TF-IDF:")
    print("=" * 40)
    
    # R√©cup√©ration des features (termes)
    feature_names = vectorizer.get_feature_names_out()
    
    print(f"üìä Nombre total de features: {len(feature_names)}")
    print(f"üìã Top 20 features les plus importantes:")
    
    # Combinaison de toutes les comp√©tences pour l'analyse
    all_skills = cv_skills + job_skills
    
    # Calcul des scores TF-IDF moyens par feature
    tfidf_matrix = vectorizer.transform(all_skills)
    feature_importance = np.mean(tfidf_matrix.toarray(), axis=0)
    
    # Top 20 features par importance
    top_features_idx = np.argsort(feature_importance)[::-1][:20]
    
    for i, idx in enumerate(top_features_idx):
        feature_name = feature_names[idx]
        importance = feature_importance[idx]
        print(f"  {i+1:2d}. {feature_name:<20} (Score: {importance:.4f})")
    
    # Analyse des n-grammes
    print(f"\nüìù Analyse des n-grammes:")
    unigrams = [f for f in feature_names if ' ' not in f]
    bigrams = [f for f in feature_names if f.count(' ') == 1]
    trigrams = [f for f in feature_names if f.count(' ') == 2]
    
    print(f"  Unigrammes: {len(unigrams)}")
    print(f"  Bigrammes: {len(bigrams)}")
    print(f"  Trigrammes: {len(trigrams)}")

def test_matching():
    """Test du matching avec des donn√©es simul√©es et TF-IDF optimis√©"""
    print("\nüß™ Test du matching TF-IDF avec des donn√©es simul√©es")
    print("=" * 60)
    
    # Donn√©es de test (simulation de CVs) - plus vari√©es et r√©alistes
    cv_skills = [
        "Python, Data Science, Machine Learning, Deep Learning, Pandas, NumPy, Scikit-learn, TensorFlow, Keras",
        "Java, Spring Boot, REST APIs, Microservices, Hibernate, Maven, JUnit, JPA, Spring Security",
        "JavaScript, React, Redux, Node.js, Express, MongoDB, HTML, CSS, TypeScript, Angular",
        "Project Management, Scrum, Agile, JIRA, Confluence, Risk Management, Stakeholder Management",
        "C++, Object-Oriented Programming, Data Structures, Algorithms, STL, Boost, Qt, OpenGL",
        "SQL, Database Design, PostgreSQL, MySQL, Data Modeling, ETL, Data Warehousing, NoSQL",
        "DevOps, Docker, Kubernetes, CI/CD, Jenkins, Git, Linux, AWS, Azure, Terraform",
        "UI/UX Design, Figma, Adobe Creative Suite, User Research, Prototyping, Wireframing",
        "Python, Web Development, Django, Flask, FastAPI, SQLAlchemy, Celery, Redis",
        "Data Engineering, Apache Spark, Hadoop, Kafka, Airflow, Delta Lake, Snowflake"
    ]
    
    # Comp√©tences requises pour les jobs - plus sp√©cifiques
    job_skills = [
        "Python, Data Science, Machine Learning, Deep Learning, Neural Networks",
        "Java, Spring Boot, Microservices, Cloud Native, Docker, Kubernetes",
        "JavaScript, React, TypeScript, Modern Web Development, REST APIs",
        "Project Management, Agile, Scrum, Team Leadership, Stakeholder Communication",
        "Data Engineering, Big Data, Apache Spark, ETL, Data Pipeline"
    ]
    
    print(f"üìä {len(cv_skills)} CVs simul√©s")
    print(f"üíº {len(job_skills)} offres d'emploi")
    print("\nüìã Comp√©tences des jobs:")
    for i, skills in enumerate(job_skills):
        print(f"  Job {i+1}: {skills}")
    
    # Test du matching TF-IDF
    similarity_matrix, best_matches, best_scores, vectorizer = calculate_similarity_tfidf(cv_skills, job_skills)
    
    if similarity_matrix is not None:
        print("\nüéØ R√©sultats du matching TF-IDF:")
        print("=" * 60)
        
        # Affichage de la matrice de similarit√©
        print("\nüìä Matrice de similarit√© (CVs vs Jobs):")
        print(f"Forme: {similarity_matrix.shape}")
        
        # Meilleurs matches
        print("\nüèÜ Meilleurs matches:")
        for i, (match, score) in enumerate(zip(best_matches, best_scores)):
            print(f"  Job {i+1} ‚Üí CV {match+1} (Score: {score:.4f})")
            print(f"    Job: {job_skills[i]}")
            print(f"    CV:  {cv_skills[match]}")
            print()
        
        # D√©tail des scores pour chaque job
        print("\nüìà Scores d√©taill√©s par job:")
        for job_idx in range(len(job_skills)):
            print(f"\nJob {job_idx+1}: {job_skills[job_idx]}")
            scores = similarity_matrix[:, job_idx]
            # Top 5 CVs pour ce job
            top_cvs = np.argsort(scores)[::-1][:5]
            for rank, cv_idx in enumerate(top_cvs):
                print(f"  {rank+1}. CV {cv_idx+1}: {scores[cv_idx]:.4f}")
        
        # Analyse des features TF-IDF
        analyze_tfidf_features(vectorizer, cv_skills, job_skills)
        
        # Analyse des r√©sultats
        analyze_results(similarity_matrix, job_skills)
        
    else:
        print("‚ùå Erreur lors du calcul de similarit√© TF-IDF")

def analyze_results(similarity_matrix, job_skills):
    """Analyse des r√©sultats du matching TF-IDF"""
    print("\nüîç Analyse des r√©sultats TF-IDF:")
    print("=" * 40)
    
    # Score moyen par job
    print("\nüìà Scores moyens par job:")
    for i in range(len(job_skills)):
        avg_score = np.mean(similarity_matrix[:, i])
        max_score = np.max(similarity_matrix[:, i])
        min_score = np.min(similarity_matrix[:, i])
        print(f"Job {i+1}: Moyenne={avg_score:.4f}, Max={max_score:.4f}, Min={min_score:.4f}")
    
    # Distribution des scores
    print("\nüìä Distribution des scores:")
    all_scores = similarity_matrix.flatten()
    print(f"Score minimum: {np.min(all_scores):.4f}")
    print(f"Score maximum: {np.max(all_scores):.4f}")
    print(f"Score moyen: {np.mean(all_scores):.4f}")
    print(f"√âcart-type: {np.std(all_scores):.4f}")
    
    # Qualit√© des matches avec seuils adapt√©s au TF-IDF
    print("\nüéØ Qualit√© des matches TF-IDF:")
    high_quality = np.sum(all_scores > 0.6)
    medium_quality = np.sum((all_scores > 0.2) & (all_scores <= 0.6))
    low_quality = np.sum(all_scores <= 0.2)
    
    print(f"Matches de haute qualit√© (>0.6): {high_quality}")
    print(f"Matches de qualit√© moyenne (0.2-0.6): {medium_quality}")
    print(f"Matches de faible qualit√© (‚â§0.2): {low_quality}")
    
    # Analyse des corr√©lations entre jobs
    print("\nüîó Corr√©lations entre jobs:")
    job_correlations = np.corrcoef(similarity_matrix.T)
    for i in range(len(job_skills)):
        for j in range(i+1, len(job_skills)):
            corr = job_correlations[i, j]
            print(f"  Job {i+1} ‚Üî Job {j+1}: {corr:.3f}")

def create_flask_api():
    """Cr√©ation de l'API Flask pour tester le matching"""
    app = Flask(__name__)
    CORS(app)
    
    # Stockage temporaire des donn√©es
    cv_data = []
    job_data = []
    
    @app.route('/')
    def home():
        return jsonify({
            'message': 'API de Matching de Comp√©tences',
            'endpoints': {
                'GET /': 'Cette page d\'accueil',
                'POST /cv': 'Ajouter un CV',
                'POST /job': 'Ajouter un job',
                'GET /match': 'Obtenir les recommandations',
                'GET /cv': 'Lister tous les CVs',
                'GET /job': 'Lister tous les jobs'
            }
        })
    
    @app.route('/cv', methods=['POST'])
    def add_cv():
        data = request.get_json()
        if 'skills' in data:
            cv_data.append({
                'id': len(cv_data) + 1,
                'skills': data['skills'],
                'name': data.get('name', f'CV {len(cv_data) + 1}')
            })
            return jsonify({'message': 'CV ajout√©', 'cv_id': len(cv_data)})
        return jsonify({'error': 'Skills requis'}), 400
    
    @app.route('/cv', methods=['GET'])
    def get_cvs():
        return jsonify(cv_data)
    
    @app.route('/job', methods=['POST'])
    def add_job():
        data = request.get_json()
        if 'skills' in data:
            job_data.append({
                'id': len(job_data) + 1,
                'skills': data['skills'],
                'title': data.get('title', f'Job {len(job_data) + 1}')
            })
            return jsonify({'message': 'Job ajout√©', 'job_id': len(job_data)})
        return jsonify({'error': 'Skills requis'}), 400
    
    @app.route('/job', methods=['GET'])
    def get_jobs():
        return jsonify(job_data)
    
    @app.route('/match', methods=['GET'])
    def get_matches():
        if not cv_data or not job_data:
            return jsonify({'error': 'Aucun CV ou job disponible'}), 400
        
        # Extraction des comp√©tences
        cv_skills_list = [cv['skills'] for cv in cv_data]
        job_skills_list = [job['skills'] for job in job_data]
        
        # Calcul de similarit√©
        similarity_matrix, best_matches, best_scores, vectorizer = calculate_similarity_tfidf(cv_skills_list, job_skills_list)
        
        if similarity_matrix is None:
            return jsonify({'error': 'Erreur lors du calcul'}), 500
        
        # Formatage des r√©sultats
        results = []
        for job_idx in range(len(job_data)):
            job_scores = similarity_matrix[:, job_idx]
            # Top 3 CVs pour ce job
            top_cvs = np.argsort(job_scores)[::-1][:3]
            
            job_result = {
                'job': job_data[job_idx],
                'recommendations': []
            }
            
            for rank, cv_idx in enumerate(top_cvs):
                job_result['recommendations'].append({
                    'rank': rank + 1,
                    'cv': cv_data[cv_idx],
                    'score': float(job_scores[cv_idx])
                })
            
            results.append(job_result)
        
        return jsonify({
            'similarity_matrix': similarity_matrix.tolist(),
            'results': results
        })
    
    return app, cv_data, job_data

def show_improvements():
    """Affiche les am√©liorations possibles du syst√®me TF-IDF"""
    print("\nüéØ Am√©liorations possibles du syst√®me TF-IDF:")
    print("=" * 50)
    print("\n1. üî§ Pr√©traitement avanc√© du texte:")
    print("   - Nettoyage des caract√®res sp√©ciaux ‚úì")
    print("   - Lemmatisation et stemming avec NLTK")
    print("   - Gestion des synonymes et acronymes")
    print("   - Normalisation des termes techniques")
    
    print("\n2. üß† Optimisations TF-IDF:")
    print("   - Ajustement dynamique des param√®tres max_features")
    print("   - Utilisation de stop words personnalis√©s")
    print("   - Pond√©ration des n-grammes par importance")
    print("   - Cache des vectoriseurs pour les performances")
    
    print("\n3. üß† Mod√®les plus avanc√©s:")
    print("   - Word2Vec ou BERT pour l'embeddings s√©mantiques")
    print("   - Mod√®les de deep learning avec attention")
    print("   - Apprentissage par renforcement pour l'optimisation")
    print("   - Mod√®les hybrides TF-IDF + embeddings")
    
    print("\n4. üìä M√©triques et analyses:")
    print("   - Similarit√© s√©mantique avanc√©e ‚úì")
    print("   - Pond√©ration par niveau d'expertise")
    print("   - Historique des matches r√©ussis")
    print("   - Analyse des patterns de comp√©tences")
    
    print("\n5. üé® Interface et fonctionnalit√©s:")
    print("   - Upload de fichiers PDF ‚úì")
    print("   - Visualisation interactive des r√©sultats")
    print("   - Export des recommandations en CSV/PDF")
    print("   - Dashboard de monitoring des performances")
    
    print("\n‚úÖ Ce fichier d√©montre l'utilisation optimis√©e de TF-IDF pour le matching de comp√©tences!")
    print("üöÄ Le syst√®me est maintenant pr√™t pour la production avec des am√©liorations continues.")

def main():
    """Fonction principale avec matching TF-IDF optimis√©"""
    print("üéØ Test du Matching de Comp√©tences avec TF-IDF et Flask")
    print("=" * 60)
    
    # Test du matching TF-IDF
    test_matching()
    
    # Cr√©ation de l'API Flask
    print("\nüåê Cr√©ation de l'API Flask avec TF-IDF...")
    app, cv_data, job_data = create_flask_api()
    
    # Ajout de donn√©es de test plus r√©alistes
    cv_data.extend([
        {'id': 1, 'name': 'CV Test 1', 'skills': 'Python, Data Science, Machine Learning, Deep Learning'},
        {'id': 2, 'name': 'CV Test 2', 'skills': 'Java, Spring Boot, REST APIs, Microservices'},
        {'id': 3, 'name': 'CV Test 3', 'skills': 'JavaScript, React, Node.js, MongoDB, Express'},
        {'id': 4, 'name': 'CV Test 4', 'skills': 'DevOps, Docker, Kubernetes, CI/CD, AWS'}
    ])
    
    job_data.extend([
        {'id': 1, 'title': 'Data Scientist', 'skills': 'Python, Machine Learning, Deep Learning, Neural Networks'},
        {'id': 2, 'title': 'Backend Developer', 'skills': 'Java, Spring Boot, Microservices, Cloud Native'},
        {'id': 3, 'title': 'Full Stack Developer', 'skills': 'JavaScript, React, Node.js, Modern Web Development'},
        {'id': 4, 'title': 'DevOps Engineer', 'skills': 'Docker, Kubernetes, CI/CD, Cloud Infrastructure'}
    ])
    
    print(f"‚úÖ {len(cv_data)} CVs et {len(job_data)} jobs ajout√©s pour les tests TF-IDF")
    
    # Affichage des am√©liorations
    show_improvements()
    
    # D√©marrage de l'API
    print("\nüöÄ D√©marrage de l'API Flask avec TF-IDF...")
    print("üì± Acc√©dez √† http://localhost:5000")
    print("üîå Utilisez Postman ou curl pour tester les endpoints")
    print("\nüìã Exemples de requ√™tes TF-IDF:")
    print("  POST /cv: {\"skills\": \"Python, Data Science, Machine Learning\"}")
    print("  POST /job: {\"skills\": \"Python, ML, Deep Learning\"}")
    print("  GET /match: Obtenir les recommandations TF-IDF")
    print("\nüîç Le syst√®me utilise maintenant TF-IDF optimis√© pour un matching plus pr√©cis!")
    print("\n‚èπÔ∏è  Appuyez sur Ctrl+C pour arr√™ter l'API")
    
    app.run(debug=True, host='0.0.0.0', port=5000)

if __name__ == '__main__':
    main()
