#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üß™ Test du Syst√®me TF-IDF de Matching de Comp√©tences

Ce fichier teste sp√©cifiquement le syst√®me TF-IDF optimis√©
pour le matching de comp√©tences entre CVs et offres d'emploi.
"""

import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from skills_preprocessor import create_preprocessor
from tfidf_config import get_tfidf_config, get_quality_thresholds

def test_tfidf_vectorizer():
    """Test du vectoriseur TF-IDF optimis√©"""
    print("üß™ Test du Vectoriseur TF-IDF")
    print("=" * 50)
    
    # Configuration TF-IDF
    config = get_tfidf_config()
    print(f"üìä Configuration TF-IDF: {len(config)} param√®tres")
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    # Donn√©es de test
    cv_skills = [
        "Python, Data Science, Machine Learning, Deep Learning, Pandas, NumPy, Scikit-learn",
        "Java, Spring Boot, REST APIs, Microservices, Hibernate, Maven, JUnit",
        "JavaScript, React, Redux, Node.js, Express, MongoDB, HTML, CSS",
        "Project Management, Scrum, Agile, JIRA, Confluence, Risk Management",
        "C++, Object-Oriented Programming, Data Structures, Algorithms, STL"
    ]
    
    job_skills = [
        "Python, Data Science, Machine Learning",
        "Java, Spring Boot, REST APIs",
        "JavaScript, React, Redux",
        "Project Management, Scrum, Agile"
    ]
    
    print(f"\nüìã Donn√©es de test:")
    print(f"  CVs: {len(cv_skills)}")
    print(f"  Jobs: {len(job_skills)}")
    
    # Cr√©ation du vectoriseur
    vectorizer = TfidfVectorizer(**config)
    
    # Combinaison des comp√©tences
    all_skills = cv_skills + job_skills
    
    # Vectorisation
    tfidf_matrix = vectorizer.fit_transform(all_skills)
    
    print(f"\n‚úÖ Vectorisation r√©ussie!")
    print(f"  Forme de la matrice: {tfidf_matrix.shape}")
    print(f"  Nombre de features: {len(vectorizer.get_feature_names_out())}")
    
    # S√©paration des vecteurs
    cv_vectors = tfidf_matrix[:len(cv_skills)]
    job_vectors = tfidf_matrix[len(cv_skills):]
    
    # Calcul de similarit√©
    similarity_matrix = cosine_similarity(cv_vectors, job_vectors)
    
    print(f"\nüéØ Matrice de similarit√©:")
    print(f"  Forme: {similarity_matrix.shape}")
    print(f"  Scores min/max: {similarity_matrix.min():.4f} / {similarity_matrix.max():.4f}")
    
    return vectorizer, similarity_matrix, cv_skills, job_skills

def test_preprocessing_impact():
    """Test de l'impact du pr√©traitement sur les r√©sultats TF-IDF"""
    print("\nüîß Test de l'Impact du Pr√©traitement")
    print("=" * 50)
    
    # Cr√©ation du pr√©traiteur
    preprocessor = create_preprocessor()
    
    # Comp√©tences avec et sans pr√©traitement
    raw_skills = [
        "Python, ML, Deep Learning, TensorFlow",
        "Java, Spring, REST APIs, Microservices",
        "JS, React, Node.js, MongoDB",
        "DevOps, Docker, K8s, CI/CD, AWS"
    ]
    
    processed_skills = preprocessor.preprocess_skills_batch(raw_skills)
    
    print("üìù Comparaison avant/apr√®s pr√©traitement:")
    for i, (raw, processed) in enumerate(zip(raw_skills, processed_skills)):
        print(f"\nComp√©tences {i+1}:")
        print(f"  Avant: {raw}")
        print(f"  Apr√®s:  {processed}")
    
    # Statistiques
    stats = preprocessor.get_skills_statistics(raw_skills)
    print(f"\nüìä Statistiques du pr√©traitement:")
    print(f"  Total comp√©tences: {stats['total_skills']}")
    print(f"  Total tokens: {stats['total_tokens']}")
    print(f"  Tokens uniques: {stats['unique_tokens']}")
    print(f"  Synonymes d√©velopp√©s: {stats['synonyms_expanded']}")
    
    return raw_skills, processed_skills

def test_similarity_metrics():
    """Test des diff√©rentes m√©triques de similarit√©"""
    print("\nüìä Test des M√©triques de Similarit√©")
    print("=" * 50)
    
    # Donn√©es de test
    cv_skills = [
        "Python, Data Science, Machine Learning, Deep Learning",
        "Java, Spring Boot, Microservices, Cloud Native",
        "JavaScript, React, TypeScript, Modern Web Development",
        "Data Engineering, Big Data, Apache Spark, ETL"
    ]
    
    job_skills = [
        "Python, Machine Learning, Deep Learning, Neural Networks",
        "Java, Spring Boot, Microservices, Docker, Kubernetes",
        "JavaScript, React, TypeScript, REST APIs",
        "Data Engineering, Big Data, Apache Spark, Data Pipeline"
    ]
    
    # Configuration TF-IDF
    config = get_tfidf_config()
    vectorizer = TfidfVectorizer(**config)
    
    # Vectorisation
    all_skills = cv_skills + job_skills
    tfidf_matrix = vectorizer.fit_transform(all_skills)
    
    # S√©paration des vecteurs
    cv_vectors = tfidf_matrix[:len(cv_skills)]
    job_vectors = tfidf_matrix[len(cv_skills):]
    
    # Diff√©rentes m√©triques de similarit√©
    metrics = {
        'cosine': cosine_similarity,
        'euclidean': lambda x, y: 1 / (1 + np.linalg.norm(x.toarray()[:, np.newaxis] - y.toarray(), axis=2)),
        'manhattan': lambda x, y: 1 / (1 + np.sum(np.abs(x.toarray()[:, np.newaxis] - y.toarray()), axis=2))
    }
    
    print("üîç Comparaison des m√©triques de similarit√©:")
    
    for metric_name, metric_func in metrics.items():
        try:
            similarity_matrix = metric_func(cv_vectors, job_vectors)
            print(f"\n  {metric_name.upper()}:")
            print(f"    Forme: {similarity_matrix.shape}")
            print(f"    Scores min/max: {similarity_matrix.min():.4f} / {similarity_matrix.max():.4f}")
            print(f"    Score moyen: {similarity_matrix.mean():.4f}")
        except Exception as e:
            print(f"\n  {metric_name.upper()}: Erreur - {e}")
    
    return vectorizer, cv_skills, job_skills

def test_quality_thresholds():
    """Test des seuils de qualit√© pour le matching"""
    print("\nüéØ Test des Seuils de Qualit√©")
    print("=" * 50)
    
    # Configuration des seuils
    thresholds = get_quality_thresholds()
    print(f"üìä Seuils configur√©s:")
    for key, value in thresholds.items():
        print(f"  {key}: {value}")
    
    # G√©n√©ration de scores simul√©s
    np.random.seed(42)  # Pour la reproductibilit√©
    simulated_scores = np.random.uniform(0, 1, 100)
    
    print(f"\nüìà Analyse des scores simul√©s:")
    print(f"  Nombre de scores: {len(simulated_scores)}")
    print(f"  Score min/max: {simulated_scores.min():.4f} / {simulated_scores.max():.4f}")
    print(f"  Score moyen: {simulated_scores.mean():.4f}")
    
    # Application des seuils
    high_quality = np.sum(simulated_scores > thresholds['high_quality'])
    medium_quality = np.sum((simulated_scores > thresholds['medium_quality']) & 
                           (simulated_scores <= thresholds['high_quality']))
    low_quality = np.sum(simulated_scores <= thresholds['medium_quality'])
    
    print(f"\nüéØ R√©partition par qualit√©:")
    print(f"  Haute qualit√© (>{thresholds['high_quality']}): {high_quality} ({high_quality/len(simulated_scores)*100:.1f}%)")
    print(f"  Qualit√© moyenne ({thresholds['medium_quality']}-{thresholds['high_quality']}): {medium_quality} ({medium_quality/len(simulated_scores)*100:.1f}%)")
    print(f"  Faible qualit√© (‚â§{thresholds['medium_quality']}): {low_quality} ({low_quality/len(simulated_scores)*100:.1f}%)")
    
    return simulated_scores, thresholds

def test_performance_optimization():
    """Test des optimisations de performance"""
    print("\n‚ö° Test des Optimisations de Performance")
    print("=" * 50)
    
    import time
    
    # Donn√©es de test de grande taille
    cv_skills = [
        f"Skill_{i}, Technology_{i}, Framework_{i}, Language_{i}, Tool_{i}"
        for i in range(100)
    ]
    
    job_skills = [
        f"Job_Skill_{i}, Job_Tech_{i}, Job_Framework_{i}"
        for i in range(20)
    ]
    
    print(f"üìä Donn√©es de test:")
    print(f"  CVs: {len(cv_skills)}")
    print(f"  Jobs: {len(job_skills)}")
    
    # Configuration TF-IDF optimis√©e
    config = get_tfidf_config()
    
    # Test avec diff√©rents param√®tres de performance
    performance_configs = [
        {'max_features': 1000, 'dtype': 'float32'},
        {'max_features': 2000, 'dtype': 'float32'},
        {'max_features': 5000, 'dtype': 'float32'}
    ]
    
    for i, perf_config in enumerate(performance_configs):
        print(f"\nüîß Configuration {i+1}: {perf_config}")
        
        # Mise √† jour de la configuration
        test_config = config.copy()
        test_config.update(perf_config)
        
        # Mesure du temps
        start_time = time.time()
        
        vectorizer = TfidfVectorizer(**test_config)
        all_skills = cv_skills + job_skills
        tfidf_matrix = vectorizer.fit_transform(all_skills)
        
        # S√©paration et calcul de similarit√©
        cv_vectors = tfidf_matrix[:len(cv_skills)]
        job_vectors = tfidf_matrix[len(job_skills):]
        similarity_matrix = cosine_similarity(cv_vectors, job_vectors)
        
        end_time = time.time()
        
        print(f"  ‚è±Ô∏è  Temps d'ex√©cution: {end_time - start_time:.4f}s")
        print(f"  üìä Forme de la matrice: {similarity_matrix.shape}")
        print(f"  üíæ Nombre de features: {len(vectorizer.get_feature_names_out())}")
    
    return cv_skills, job_skills

def main():
    """Fonction principale de test"""
    print("üß™ Test Complet du Syst√®me TF-IDF de Matching de Comp√©tences")
    print("=" * 70)
    
    try:
        # Test 1: Vectoriseur TF-IDF
        vectorizer, similarity_matrix, cv_skills, job_skills = test_tfidf_vectorizer()
        
        # Test 2: Impact du pr√©traitement
        raw_skills, processed_skills = test_preprocessing_impact()
        
        # Test 3: M√©triques de similarit√©
        vectorizer2, cv_skills2, job_skills2 = test_similarity_metrics()
        
        # Test 4: Seuils de qualit√©
        simulated_scores, thresholds = test_quality_thresholds()
        
        # Test 5: Optimisations de performance
        large_cv_skills, large_job_skills = test_performance_optimization()
        
        print("\n‚úÖ Tous les tests TF-IDF ont √©t√© ex√©cut√©s avec succ√®s!")
        print("üöÄ Le syst√®me est pr√™t pour la production!")
        
    except Exception as e:
        print(f"\n‚ùå Erreur lors des tests: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
